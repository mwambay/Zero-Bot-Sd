
import os
import sys
chemin_parent = os.path.abspath(os.path.join(os.path.dirname(__file__), ".."))
sys.path.append(chemin_parent)
import torch
import re
from transformers import GPT2LMHeadModel, GPT2TokenizerFast
from collections import OrderedDict
from data.manage_data import save_file


class GPT2PPL:
    def __init__(self, device="cpu", model_id="gpt2"):
        self.device = device
        self.model_id = model_id
        self.model = GPT2LMHeadModel.from_pretrained(model_id).to(device)
        self.tokenizer = GPT2TokenizerFast.from_pretrained(model_id)

        self.max_length = self.model.config.n_positions
        self.stride = 512
        
    def getResults(self, threshold, threshold_ai = 200, threshold_mixte = 280):
        print("threshold : " , threshold)
        if  threshold < threshold_ai: # threshold < 60:
            label = 0
            return "Texte generé par une IA.", label
        elif threshold < threshold_mixte: #threshold < 80:
            label = 0
            return "The Text is most probably contain parts which are generated by AI. (require more text for better Judgement)", label
        else:
            label = 1
            return "Texte generé par un Humain.", label

    def __call__(self, sentence, threshold_ai = 200, threshold_mixte = 280, lines = None):
        """
        Takes in a sentence split by full stop
        and print the perplexity of the total sentence

        split the lines based on full stop and find the perplexity of each sentence and print
        average perplexity

        Burstiness is the max perplexity of each sentence
        """
        save_file('observation', 'json', {"observation" : 'Use GPT-2'})
        results = OrderedDict()

        total_valid_char = re.findall("[a-zA-Z0-9]+", sentence)
        total_valid_char = sum([len(x) for x in total_valid_char]) # finds len of all the valid characters a sentence

        if total_valid_char < 100:
            return {"status": "Please input more text (min 100 characters)"}, "Please input more text (min 100 characters)"
        
        if lines is None:
            lines = re.split(r'(?<=[.?!][ \[\(])|(?<=\n)\s*',sentence)
            
        lines = list(filter(lambda x: (x is not None) and (len(x) > 0), lines))

        ppl = self.getPPL(sentence)
        print(f"Perplexity {ppl}")
        results["Perplexity"] = ppl

        save_file('observation', 'json', {"observation" : 'get PPL'})

        offset = ""
        observer = False
        observation = ""
        Perplexity_per_line = []
        sentences = []
        for i, line in enumerate(lines):
            if observer:
                line = observation + " " + line
                
            if re.search("[a-zA-Z0-9]+", line) == None:
                continue
            if len(offset) > 0:
                line = offset + line
                offset = ""
            # remove the new line pr space in the first sentence if exists
            if line[0] == "\n" or line[0] == " ":
                line = line[1:]
            if line[-1] == "\n" or line[-1] == " ":
                line = line[:-1]
            elif line[-1] == "[" or line[-1] == "(":
                offset = line[-1]
                line = line[:-1]
            try : 
                ppl = self.getPPL(line)
                observer = not observer
            except ValueError:
                observer = True
                observation = line
                continue
            #if ppl <= threshold_ai:
            sentences.append(line) 
                
            Perplexity_per_line.append(ppl)
        
        save_file('observation', 'json', {"observation" : 'summaryL'})
        
        print(f"Perplexity per line {sum(Perplexity_per_line)/len(Perplexity_per_line)}")
        results["Perplexity per line"] = sum(Perplexity_per_line)/len(Perplexity_per_line)
        
        print(f"Burstiness {max(Perplexity_per_line)}")
        results["Burstiness"] = max(Perplexity_per_line)
        
        out, label = self.getResults(results["Perplexity per line"], threshold_ai, threshold_mixte)
        results["label"] = label
        print(f"results {results}")
        save_file('observation', 'json', {"observation" : 'End'})
        print(Perplexity_per_line)
        
        return results, sentences, Perplexity_per_line, out

    def getPPL(self,sentence):
        encodings = self.tokenizer(sentence, return_tensors="pt")
        #print("\n\nencoding : ", encodings, "\n\n")
        seq_len = encodings.input_ids.size(1)
        nlls = []
        likelihoods = []
        prev_end_loc = 0
        for begin_loc in range(0, seq_len, self.stride):
            end_loc = min(begin_loc + self.max_length, seq_len)
            trg_len = end_loc - prev_end_loc
            input_ids = encodings.input_ids[:, begin_loc:end_loc].to(self.device)
            target_ids = input_ids.clone()
            target_ids[:, :-trg_len] = -100

            with torch.no_grad():
                outputs = self.model(input_ids, labels=target_ids)
                neg_log_likelihood = outputs.loss * trg_len
                likelihoods.append(neg_log_likelihood)

            nlls.append(neg_log_likelihood)

            prev_end_loc = end_loc
            if end_loc == seq_len:
                break
        ppl = int(torch.exp(torch.stack(nlls).sum() / end_loc))
        return ppl
